{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nCreated on Sep 11 2018\\n\\n@author: Fernanda Farinelli\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Sep 11 2018\n",
    "\n",
    "@author: Fernanda Farinelli\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "consumer_key = 'rWxMBAKB6IgXNVrsXkisVebMU'\n",
    "consumer_secret = 'xRFc47WcbcgoZYb26OHfMXakda7UFIQMvZw2WftbOsAXpBRKMS'\n",
    "access_token_key = '1028301224519589889-hrC4g78bb0PJ9RiEbusi657it517wf'\n",
    "access_token_secret = 'hhwamERYlZUJuLQwWnJtvWvqpB5hFCyNBOCiDVDrT5xIL'\n",
    "filename = \"C://Users//unesp//ProjetoOpLaDyn//twitter_tokens_pt.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy #https://github.com/tweepy/tweepy\n",
    "import csv\n",
    "import json\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_tweets(search_query):\n",
    "\t#Twitter only allows access to a users most recent 3240 tweets with this method\n",
    "\t\n",
    "\t#authorize twitter, initialize tweepy\n",
    "\tauth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "\tauth.set_access_token(access_token_key, access_token_secret)\n",
    "\tapi = tweepy.API(auth)\n",
    "\t\n",
    "\t#initialize a list to hold all the tweepy Tweets\n",
    "\talltweets = []\n",
    "\t\n",
    "\tprint(search_query)\n",
    "\t#make initial request for most recent tweets (200 is the maximum allowed count)\n",
    "\tnew_tweets = api.search(search_query, count=200)\n",
    "\t#new_tweets = api.user_timeline(screen_name = screen_name,count=200)    \n",
    "\tprint('new_tweets',len(new_tweets))\n",
    "\t#save most recent tweets\n",
    "\talltweets.extend(new_tweets)\n",
    "\t\n",
    "\t#save the id of the oldest tweet less one\n",
    "\toldest = alltweets[-1].id - 1\n",
    "\t\n",
    "\t#keep grabbing tweets until there are no tweets left to grab\n",
    "\twhile len(new_tweets) > 0:\n",
    "\t\tprint (\"getting tweets before %s\" % (oldest))\n",
    "\t\t\n",
    "\t\t#all subsiquent requests use the max_id param to prevent duplicates\n",
    "\t\t#new_tweets = api.user_timeline(screen_name = screen_name,count=200,max_id=oldest)\n",
    "\t\tnew_tweets = api.user_timeline(screen_name = screen_name,count=200,max_id=oldest)        \n",
    "\t\t\n",
    "\t\t#save most recent tweets\n",
    "\t\talltweets.extend(new_tweets)\n",
    "\t\t#print(\"type alltweets\",type(alltweets))\n",
    "\t\t#print(\"type new_tweets\",type(new_tweets))\n",
    "\t\t\n",
    "\t\t#update the id of the oldest tweet less one\n",
    "\t\toldest = alltweets[-1].id - 1\n",
    "\t\t\n",
    "\t\tprint (\"...%s tweets downloaded so far\" % (len(alltweets)))\n",
    "\t\n",
    "\ttimestr = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "\tprint(timestr)\n",
    "\n",
    "\tfilename = \"tweetsKeywords_pt\" + timestr\n",
    "    \n",
    "\t#write tweet objects to JSON\n",
    "\t#file = open('tweet.json', 'wb')\n",
    "\tfile = open(filename + '.json','w')\n",
    "\tprint (\"Writing tweet objects to JSON please wait...\")\n",
    "\tfor status in alltweets:\n",
    "\t\tjson.dump(status._json,file,sort_keys = True,indent = 4)\n",
    "\t#close the file\n",
    "\tprint (\"Done with JSON\")\n",
    "\tfile.close()\n",
    "    \n",
    "\t#transform the tweepy tweets into a 2D array that will populate the csv\t\n",
    "\tprint (\"...writing csv - step 1\")\n",
    "\touttweets = [[tweet.id_str, tweet.created_at, tweet.text.encode(\"utf-8\")] for tweet in alltweets]\n",
    "\t#write the csv\t\n",
    "\t#file = open(filename + '.csv','wb')    \n",
    "\t#with open('%s_tweets.csv' % screen_name, 'w') as f:\n",
    "\twith open(filename + '.csv', 'w') as f:\n",
    "\t\tprint (\"...writing csv\")        \n",
    "\t\twriter = csv.writer(f)\n",
    "\t\twriter.writerow([\"id\",\"created_at\",\"text\"])        \n",
    "\t\twriter.writerows(outtweets)\n",
    "\t\t \n",
    "\tpass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"'feminicidio'\", \"'femicídio'\", \"'crime passional'\", \"'defesa da honra'\", \"'maria da penha'\", \"'vadia da penha'\", \"'assassinato de mulher'\", \"'homicídio de mulher'\", \"'essa vadia'\", \"'aquela vadia'\\n\"]\n",
      "Search string:  'feminicidio' or 'femicídio' or 'crime passional' or 'defesa da honra' or 'maria da penha' or 'vadia da penha' or 'assassinato de mulher' or 'homicídio de mulher' or 'essa vadia' or 'aquela vadia'\n"
     ]
    }
   ],
   "source": [
    "\n",
    "with open(filename, 'r') as twitter_tokens:\n",
    "    tokens = twitter_tokens.read().split(',')\n",
    "    print(tokens)\n",
    "\n",
    "SEARCH_TERM = ''\n",
    "i=0\n",
    "\n",
    "while i < len(tokens):\n",
    "    if i == 0:\n",
    "        SEARCH_TERM = tokens[i].strip()\n",
    "    else:\n",
    "        SEARCH_TERM = SEARCH_TERM + ' or '+ tokens[i].strip()\n",
    "    #print(str(i),': ',SEARCH_TERM)\n",
    "    i = i + 1\n",
    "\n",
    "q=str(query)\n",
    "   a=str(q+\" sarcasm\")\n",
    "   b=str(q+\" sarcastic\")\n",
    "   c=str(q+\" irony\")\n",
    "   fetched_tweets = api.search(a, count = count)+ api.search(b, count = count)+ api.search(c, count = count)\n",
    "   # parsing tweets one by one\n",
    "   print(len(fetched_tweets))    \n",
    "    \n",
    "print('Search string: ',SEARCH_TERM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'feminicidio' or 'femicídio' or 'crime passional' or 'defesa da honra' or 'maria da penha' or 'vadia da penha' or 'assassinato de mulher' or 'homicídio de mulher' or 'essa vadia' or 'aquela vadia'\n",
      "new_tweets 0\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-4a804afd0ccd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'__main__'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m         \u001b[1;31m#pass in the username of the account you want to download\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m         \u001b[0mget_all_tweets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mSEARCH_TERM\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-10-65962bfee57d>\u001b[0m in \u001b[0;36mget_all_tweets\u001b[1;34m(search_query)\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m         \u001b[1;31m#save the id of the oldest tweet less one\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m         \u001b[0moldest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0malltweets\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mid\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m         \u001b[1;31m#keep grabbing tweets until there are no tweets left to grab\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "\t#pass in the username of the account you want to download\n",
    "\tget_all_tweets(SEARCH_TERM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
