{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nCreated on Sep 12 2018\\n@author: Fernanda Farinelli\\n\\nResource Information\\n    Response formats --> JSON\\n    Requires authentication? --> Yes\\n    Rate limited? --> Yes\\n    Requests / 15-min window (user auth) --> 180\\n    Requests / 15-min window (app auth) --> 450\\n\\n\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Sep 12 2018\n",
    "@author: Fernanda Farinelli\n",
    "\n",
    "Resource Information\n",
    "    Response formats --> JSON\n",
    "    Requires authentication? --> Yes\n",
    "    Rate limited? --> Yes\n",
    "    Requests / 15-min window (user auth) --> 180\n",
    "    Requests / 15-min window (app auth) --> 450\n",
    "\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Globals variables and constants\n",
    "\n",
    "consumer_key = 'rWxMBAKB6IgXNVrsXkisVebMU'\n",
    "consumer_secret = 'xRFc47WcbcgoZYb26OHfMXakda7UFIQMvZw2WftbOsAXpBRKMS'\n",
    "access_token_key = '1028301224519589889-hrC4g78bb0PJ9RiEbusi657it517wf'\n",
    "access_token_secret = 'hhwamERYlZUJuLQwWnJtvWvqpB5hFCyNBOCiDVDrT5xIL'\n",
    "#filename = \"C://Users//unesp//ProjetoOpLaDyn//inputs//twitter_tokens_pt.txt\"\n",
    "fileInput = \"C://Users//unesp//ProjetoOpLaDyn//inputs//twitter_tokens_Marielle_pt.txt\"\n",
    "folderOutput = 'C:\\\\Users\\\\unesp\\\\ProjetoOpLaDyn\\\\outputs\\\\'\n",
    "\n",
    "#Using the standard search endpoint\n",
    "resourceURL = \"https://api.twitter.com/1.1/search/tweets.json\"\n",
    "queryURL = \"?l=pt&q=%23Marielle%20OR%20%23MarielleFranco%20OR%20%23MariellePresente%20OR%20%23Justi%C3%A7aParaMarielleEAnderson%20OR%20%23QuemMatouMarielle%20since%3A2018-09-01%20until%3A2018-09-02&src=typd\"\n",
    "\n",
    "completeQueryURL = \"https://api.twitter.com/1.1/search/tweets.json?l=pt&q=%23Marielle%20OR%20%23MarielleFranco%20OR%20%23MariellePresente%20OR%20%23Justi%C3%A7aParaMarielleEAnderson%20OR%20%23QuemMatouMarielle%20since%3A2018-09-01%20until%3A2018-09-02&src=typd\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy #https://github.com/tweepy/tweepy\n",
    "import csv\n",
    "import json\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_authorize_twitter():\n",
    "    global consumer_key, consumer_secret, access_token_key, access_token_secret\n",
    "    \n",
    "    #authorize twitter, initialize tweepy\n",
    "    # Creating the authentication object\n",
    "    auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "    # Setting your access token and secret\n",
    "    auth.set_access_token(access_token_key, access_token_secret)\n",
    "    # Creating the API object while passing in auth information\n",
    "    return tweepy.API(auth)\n",
    "\n",
    "def writeJSON(alltweets,timestr):\n",
    "    filename = folderOutput + \"tweetsKeywordsCaseMarielle_pt_\" + timestr\n",
    "    #write tweet objects to JSON\n",
    "    file = open(filename + '.json','w')\n",
    "    print (\"Writing tweet objects to JSON please wait...\")\n",
    "    for status in alltweets:\n",
    "        json.dump(status._json,file,sort_keys = True,indent = 4)\n",
    "    #close the file\n",
    "    print (\"Done with JSON\")\n",
    "    file.close()\n",
    "\n",
    "def writeCSV(alltweets,timestr):\n",
    "    #transform the tweepy tweets into a 2D array that will populate the csv\t\n",
    "    print (\"...writing csv - step 1\")\n",
    "    outtweets = [[tweet.id_str, tweet.created_at, tweet.text.encode(\"utf-8\")] for tweet in alltweets]\n",
    "    filename = folderOutput + \"tweetsKeywordsCaseMarielle_pt_\" + timestr\n",
    "    #write the csv\t\n",
    "    with open(filename + '.csv', 'w') as f:\n",
    "        print (\"...writing csv\")        \n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow([\"id\",\"created_at\",\"text\"])        \n",
    "        writer.writerows(outtweets)\n",
    "\n",
    "def get_all_tweets(api):\n",
    "    global resourceURL,queryURL\n",
    "    count=1000\n",
    "    rpp=100\n",
    "    fetched_tweets = ''\n",
    "    #alltweets = []\n",
    "    \n",
    "    #fetched_tweets =  tweepy.Cursor(api.search,q=queryURL,lang=\"pt\",rpp=100,count=1000,tweet_mode='extended')\n",
    "    #print('fetched_tweets:',len(fetched_tweets))\n",
    "\n",
    "    max_tweets = 1000\n",
    "    searched_tweets = [status for status in tweepy.Cursor(api.search,q=queryURL,lang=\"pt\",rpp=rpp,count=count,tweet_mode='extended').items(max_tweets)]\n",
    "    searched_tweets = []\n",
    "    last_id = -1\n",
    "    while len(searched_tweets) < max_tweets:\n",
    "        count = max_tweets - len(searched_tweets)\n",
    "        try:\n",
    "            print('queryURL:',queryURL)\n",
    "            new_tweets = api.search(q=queryURL,lang=\"pt\",rpp=rpp,count=count, max_id=str(last_id - 1),tweet_mode='extended')\n",
    "            print('new_tweets:',len(new_tweets))\n",
    "            if not new_tweets:\n",
    "                break\n",
    "            searched_tweets.extend(new_tweets)\n",
    "            last_id = new_tweets[-1].id\n",
    "        except tweepy.TweepError as e:\n",
    "            # depending on TweepError.code, one may want to retry or wait\n",
    "            # to keep things simple, we will give up on an error\n",
    "            break    \n",
    "    \n",
    "    print('searched_tweets:',len(searched_tweets))\n",
    "    #preparing file to write\n",
    "    timestr = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "    print(timestr)\n",
    "    \n",
    "    writeJSON(searched_tweets,timestr)\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "queryURL: ?l=pt&q=%23Marielle%20OR%20%23MarielleFranco%20OR%20%23MariellePresente%20OR%20%23Justi%C3%A7aParaMarielleEAnderson%20OR%20%23QuemMatouMarielle%20since%3A2018-09-01%20until%3A2018-09-02&src=typd\n",
      "new_tweets: 0\n",
      "searched_tweets: 0\n",
      "20180912-162045\n",
      "Writing tweet objects to JSON please wait...\n",
      "Done with JSON\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    \n",
    "    api = get_authorize_twitter()\n",
    "    get_all_tweets(api)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
