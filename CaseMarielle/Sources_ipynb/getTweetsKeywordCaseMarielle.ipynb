{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nCreated on Sep 11 2018\\n\\n@author: Fernanda Farinelli\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Sep 11 2018\n",
    "\n",
    "@author: Fernanda Farinelli\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "consumer_key = 'rWxMBAKB6IgXNVrsXkisVebMU'\n",
    "consumer_secret = 'xRFc47WcbcgoZYb26OHfMXakda7UFIQMvZw2WftbOsAXpBRKMS'\n",
    "access_token_key = '1028301224519589889-hrC4g78bb0PJ9RiEbusi657it517wf'\n",
    "access_token_secret = 'hhwamERYlZUJuLQwWnJtvWvqpB5hFCyNBOCiDVDrT5xIL'\n",
    "#filename = \"C://Users//unesp//ProjetoOpLaDyn//inputs//twitter_tokens_pt.txt\"\n",
    "fileInput = \"C://Users//unesp//ProjetoOpLaDyn//inputs//twitter_tokens_Marielle_pt.txt\"\n",
    "folderOutput = 'C:\\\\Users\\\\unesp\\\\ProjetoOpLaDyn\\\\outputs\\\\'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy #https://github.com/tweepy/tweepy\n",
    "import csv\n",
    "import json\n",
    "import time\n",
    "import unicodedata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_tweets(tokens):\n",
    "    fetched_tweets = ''\n",
    "    alltweets = []    \n",
    "\n",
    "    #authorize twitter, initialize tweepy\n",
    "    # Creating the authentication object\n",
    "    auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "    # Setting your access token and secret\n",
    "    auth.set_access_token(access_token_key, access_token_secret)\n",
    "    # Creating the API object while passing in auth information\n",
    "    api = tweepy.API(auth)\n",
    "    \n",
    "\n",
    "    i=0\n",
    "    # The search term you want to find    \n",
    "    while i < len(tokens):\n",
    "        if i == 0:\n",
    "            #SEARCH_TERM = tokens[i].strip()\n",
    "            #fetched_tweets = api.search(q=tokens[i].strip(),lang = \"pt\")\n",
    "            fetched_tweets = api.search(q=tokens[i].strip(),lang = \"pt\",rpp=100,count=1000)\n",
    "            print('Tweets to \"',tokens[i].strip(),'\" keyword:',len(fetched_tweets))\n",
    "        else:\n",
    "            #SEARCH_TERM = SEARCH_TERM + ' or '+ tokens[i].strip()\n",
    "            fetched_tweets = api.search(q=tokens[i].strip(),lang = \"pt\",rpp=100,count=1000)\n",
    "            alltweets.extend(fetched_tweets)\n",
    "            print('Tweets to \"',tokens[i].strip(),'\" keyword:',len(fetched_tweets))\n",
    "        i = i + 1\n",
    "    # parsing tweets one by one\n",
    "    print('alltweets:',len(alltweets))\n",
    "\n",
    "    #preparing file to write\n",
    "    timestr = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "    #print(timestr)\n",
    "    \n",
    "    writeJSON(alltweets,timestr)\n",
    "    writeCSV(alltweets,timestr)\n",
    "    \n",
    "    \n",
    "def writeJSON(alltweets,timestr):\n",
    "    filename = folderOutput + \"tweetsKeywordsCaseMarielle_pt_\" + timestr\n",
    "    #write tweet objects to JSON\n",
    "    file = open(filename + '.json','w')\n",
    "    print (\"Writing tweet objects to JSON please wait...\")\n",
    "    for status in alltweets:\n",
    "        json.dump(status._json,file,sort_keys = True,indent = 4)\n",
    "    #close the file\n",
    "    print (\"Done with JSON\")\n",
    "    file.close()\n",
    "\n",
    "def writeCSV(alltweets,timestr):\n",
    "    #transform the tweepy tweets into a 2D array that will populate the csv\t\n",
    "    print (\"...writing csv - step 1\")\n",
    "    #outtweets = [[tweet.id_str, tweet.created_at, tweet.entities.hashtags,tweet.text.encode(\"utf-8\")] for tweet in alltweets]\n",
    "    outtweets = [[tweet.id_str, tweet.created_at, tweet.entities.hashtags,tweet.text.encode(\"utf-8\")] for tweet in alltweets]    \n",
    "    \n",
    "unicodedata.normalize('NFKD', tweet.text).encode('ascii','ignore')\n",
    "\n",
    "    filename = folderOutput + \"tweetsKeywordsCaseMarielle_pt_\" + timestr\n",
    "    #write the csv\t\n",
    "    with open(filename + '.csv', 'w') as f:\n",
    "        print (\"...writing csv\")        \n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow([\"id\",\"created_at\",\"hashtags\",\"text\"])        \n",
    "        writer.writerows(outtweets)    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keywords list: ['\"Marielle e Anderson\"', '\"Marielle Franco\"', 'marielle', '\"quem matou marielle\"', '#Marielle', '#MarielleFranco', '#MariellePresente', '#JustiçaParaMarielleEAnderson', '\"Marielle Presente\"', '#QuemMatouMarielle\\n']\n",
      "Tweets to \" \"Marielle e Anderson\" \" keyword: 100\n",
      "Tweets to \" \"Marielle Franco\" \" keyword: 100\n",
      "Tweets to \" marielle \" keyword: 100\n",
      "Tweets to \" \"quem matou marielle\" \" keyword: 100\n",
      "Tweets to \" #Marielle \" keyword: 100\n",
      "Tweets to \" #MarielleFranco \" keyword: 100\n",
      "Tweets to \" #MariellePresente \" keyword: 100\n",
      "Tweets to \" #JustiçaParaMarielleEAnderson \" keyword: 62\n",
      "Tweets to \" \"Marielle Presente\" \" keyword: 100\n",
      "Tweets to \" #QuemMatouMarielle \" keyword: 42\n",
      "alltweets: 804\n",
      "Writing tweet objects to JSON please wait...\n",
      "Done with JSON\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    #pass in the username of the account you want to download\n",
    "    with open(fileInput, 'r') as twitter_tokens:\n",
    "        tokens = twitter_tokens.read().split(',')\n",
    "        print('Keywords list:',tokens)\n",
    "\n",
    "    get_all_tweets(tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
